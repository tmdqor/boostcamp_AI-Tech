# 통계학 (Statistics)

## 모수
* 통계적 모델링은 적절한 가정 위에서 확률분포를 추정(inference)하는 것이 목표이며 기계학습과 통계학이 공통적으로 추구하는 목표
* 그러나 유안한 개수의 데이터만 관찰해서 모집단의 분포를 정확하게 알아낸다는 것은 불가능하므로, 근사적으로 확률 분포를 추정할 수 밖에없음
* 예측모형의 목적은 분포를 정확하게 맞추는 것보다는 데이터와 추정방법의 불확실성을 고려해서 위험을 최소화하는 것
* 데이터가 특정 확률분포를 따른다고 선험적으로(a priori) 가정한 후 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 모수적 방법론이라고함
* 정규분포의 확률분포를 모델링한다면 정규분포의 모수로는 평균,분산이 있음, 평균과 분산을 추정하는 방법을 통해서 데이터를 학습하는 방법을 모수적 방법이라함
* 특정 확률분포를 가정하지 않고 데이터에 따라서 모델의 구조와 모수의 개수가 유연하게 바뀌면 비 모수방법론이라고함

## 최대가능도 추정법
* 표본평균이나 표본분산은 중요한 통계량이지만 확률분포마다 사용하는 모수가 다르므로 적절한 통계량이 달라짐
* 이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나는 최다대가능도 추정법 (maximum likelihood estimation,MLE)
* 데이터 집합 X가 독립적으로 추출되었을 경우 로그가능도를 최적화함

## 확률분포의 거리
* 기계학습에서 사용되는 손실함수들은 모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 유도됨
* 데이터 공간에 두개의 확률분포사이의 거리를 구하는 함수
    * 총변동 거리(Total Variation Distance, TV)
    * 쿨백 라이블러발산(KL Divergence)을 최소화
    * 바슈타인 거리(Wasserstein Distance)