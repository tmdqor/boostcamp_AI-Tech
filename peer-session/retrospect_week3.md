# 학습 회고

## Mon - Day 15
- **Peer-Session**  
    - 지난주의 배웠던 gather에 대해 서로 얘기하며 개념을 잡아갔다.  
    - zero_grad()를 호출해야하는 이유에 대해 PyTorch가 그래디언트를 누적하기 때문이다. 이러한 누적 동작이 RNN(순환 신경망)을 학습할 때나 여러 미니 배치에 걸쳐 손실의 그래디언트를 계산할 때 편리하기에 기본적으로 파이토치는 loss.backward()를 호출할 때마다 그래디언트를 누적하도록 설정되어있다.
- **Fact**  
: 1,2,3 강 강의를 학습하였다. 
- **Feeling**  
: 수업에서 다루지 않은 내용에 의문을 품고 동료들과 같이 개념을 하나씩 쌓아갔다. 피어세션은 점차 발전하는데 개인으로는 어떤지 잘 모르겠다. 월요병인지 오후가 되니 집중력이 많이 떨어졌다. 오늘 회고를 쓰며 반성해본다.
- **Future Plan & Finding**  
: 본격적인 torch 코드가 나와서 해당 코드에 익숙해지며 이전의 수학과 접목해 학습해야겠다.


## Tue - Day 16
- **Fact**  
: 
- **Feeling**  
: 
- **Future Plan & Finding**  
: 


## Wed - Day 17
- **Fact**  
: 
- **Feeling**  
: 
- **Future Plan & Finding**  
: 


## Thu - Day 18
- **Fact**  
: 
- **Feeling**  
: 
- **Future Plan & Finding**  
: 


## Fri - Day 19
- **Fact**  
: 
- **Feeling**  
: 
- **Future Plan & Finding**  
: 



